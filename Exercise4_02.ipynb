{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Exercise4_02.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssiKlgn8ha5d"
      },
      "source": [
        "# Exercise 4.02: Precision, Recall, and F1 Score Calculation\n",
        "\n",
        "In this exercise, we will calculate the precision, recall value, and the $F_1$ score of two different classifiers on a simulated dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks2yIxhiha5s"
      },
      "source": [
        "1.- Import the `numpy` package as `np` using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRvHZHmNha5y"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIOxJibwha56"
      },
      "source": [
        "2.- Create a `numpy` array called `real_labels` that contains the values `[True, True, False, True, True]`. This list will represent the true values of the target variable for our simulated dataset. Print its content:\n",
        "\n",
        "Output:\n",
        "\n",
        "```\n",
        "array([ True, True, False, True, True])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxRWAru8ha59",
        "outputId": "8d238952-bea4-4693-b20e-7fac147dfef9"
      },
      "source": [
        "real_labels = np.array([True, True, False, True, True])\r\n",
        "real_labels"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE57oEp9ha59"
      },
      "source": [
        "3.- Create a `numpy` array called `model_1_preds` that contains the values `[True, False, False, False, False]`. This list will represent the predicted values of the first classifier. Print its content.\n",
        "\n",
        "Output\n",
        "\n",
        "```\n",
        "array([ True, False, False, False, False])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgFD4iI6ha5-",
        "outputId": "110ecefb-c39b-4814-b70e-a540cc611a8a"
      },
      "source": [
        "\r\n",
        "model_1_preds = np.array([True, False, False, False, False])\r\n",
        "model_1_preds"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ibbj4mOha5-"
      },
      "source": [
        "4.- Create another `numpy` array `called model_2_preds` that contains the values `[True, True, True, True, True]`. This list will represent the predicted values of the first classifier. Print its content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8zetgJzha5_",
        "outputId": "fc9d0169-e754-4235-d043-e58696a8a22f"
      },
      "source": [
        "model_2_preds = np.array([True, True, True, True, True])\r\n",
        "model_2_preds"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq4dXvF3ha5_"
      },
      "source": [
        "5.- Create a variable called `model_1_tp_cond` that will find the true positives for the first model.\n",
        "\n",
        "Output:\n",
        "\n",
        "```\n",
        "array([ True, False, False, False, False])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCl27OVsha5_",
        "outputId": "fca14817-23ac-4545-b9de-27f47c8d22a9"
      },
      "source": [
        "model_1_tp_cond = (real_labels == True) & (model_1_preds == True)\r\n",
        "model_1_tp_cond"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4qJ1gU4ha6A"
      },
      "source": [
        "6.- Create a variable called `model_1_tp` that will get the number of true positives for the first model by summing `model_1_tp_cond`.\n",
        "\n",
        "Output:\n",
        "\n",
        "1\n",
        "\n",
        "There is only 1 true positive case for the first model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljcXUMjgha6A",
        "outputId": "98d33fd2-e46d-43b1-bba2-16f6795b0748"
      },
      "source": [
        "model_1_tp = model_1_tp_cond.sum()\r\n",
        "model_1_tp"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-rTzvs0ha6A"
      },
      "source": [
        "7.- Create a variable called `model_1_fp` that will get the number of false positives for the first model:\n",
        "\n",
        "Output:\n",
        "\n",
        "0\n",
        "\n",
        "There is no false positive for the first model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U6fQZRyha6B",
        "outputId": "d76ee82c-8c09-4e47-89a7-fa9d6e901a45"
      },
      "source": [
        "model_1_fp = ((real_labels == False) & (model_1_preds == True)).sum()\r\n",
        "model_1_fp"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzD0oonHha6B"
      },
      "source": [
        "8.- Create a variable called `model_1_fn` that will get the number of false negatives for the first model:\n",
        "\n",
        "Output:\n",
        "3\n",
        "\n",
        "The first classifier presents 3 false negative cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3LDCSYwha6C",
        "outputId": "4fe418ba-bcfb-438e-86ae-4fa727ed1d06"
      },
      "source": [
        "model_1_fn = ((real_labels == True) & (model_1_preds == False)).sum()\r\n",
        "model_1_fn"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MczeY6MTha6C"
      },
      "source": [
        "9.- Create a variable called `model_1_precision` that will calculate the precision for the first model:\n",
        "\n",
        "Output:\n",
        "1.0\n",
        "\n",
        "The first classifier has a precision score of 1, so it didn't predict any false positives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmYZkhiZha6C",
        "outputId": "76d8a2d2-a214-438f-bb90-6788e21af5a3"
      },
      "source": [
        "\r\n",
        "model_1_precision = model_1_tp / (model_1_tp + model_1_fp) \r\n",
        "model_1_precision"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciG8T5qRha6C"
      },
      "source": [
        "10.- Create a variable called `model_1_recall` that will calculate the recall for the first model.\n",
        "\n",
        "Output:\n",
        "0.25\n",
        "\n",
        "The recall score for the first model is only $0.25$, so it is predicting quite a lot of false negatives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exw5m3rhha6E",
        "outputId": "3989eac3-410b-433d-8ad0-1fbf2c5c5a55"
      },
      "source": [
        "model_1_recall = model_1_tp / (model_1_tp + model_1_fn)\r\n",
        "model_1_recall"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGdp6bHgha6F"
      },
      "source": [
        "11.- Create a variable called `model_1_f1` that will calculate the $F_1$ score for the first model.\n",
        "\n",
        "Output:\n",
        "0.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWhHrgRQha6G",
        "outputId": "71072102-5fce-410e-e4bf-430d3f413452"
      },
      "source": [
        "model_1_f1 = 2 * model_1_precision * model_1_recall / (model_1_precision + model_1_recall)\r\n",
        "model_1_f1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-eXNQRzha6G"
      },
      "source": [
        "12.- Create a variable called `model_2_tp` that will get the number of true positives for the second model.\n",
        "\n",
        "Output:\n",
        "4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf4aLw21ha6G",
        "outputId": "4568817c-3081-4f82-8d37-973a725b0692"
      },
      "source": [
        "\r\n",
        "model_2_tp = ((real_labels == True) & (model_2_preds == True)).sum()\r\n",
        "model_2_tp"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbX__S4Uha6H"
      },
      "source": [
        "13.- Create a variable called `model_2_fp` that will get the number of false positives for the second model\n",
        "\n",
        "Output:\n",
        "1\n",
        "\n",
        "\n",
        "There is only one false positive for the second model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-6C21kjha6H",
        "outputId": "4627a70a-96e1-49dc-ec17-fc761e2d8edc"
      },
      "source": [
        "model_2_fp = ((real_labels == False) & (model_2_preds == True)).sum()\r\n",
        "model_2_fp"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gm8yBiZha6H"
      },
      "source": [
        "14.- Create a variable called `model_2_fn` that will get the number of false negatives for the second model\n",
        "\n",
        "Output\n",
        "0\n",
        "\n",
        "There is no false negative for the second classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOtnOTJAha6I",
        "outputId": "3c902918-b3a8-4fa5-c6a1-b5b0a5f97050"
      },
      "source": [
        "\r\n",
        "model_2_fn = ((real_labels == True) & (model_2_preds == False)).sum()\r\n",
        "model_2_fn"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx4kW1fGha6I"
      },
      "source": [
        "15.- Create a variable called `model_2_precision` that will calculate precision for the second model:\n",
        "\n",
        "Output:\n",
        "0.8\n",
        "\n",
        "The precision score for the second model is quite high: 0.8. It is not making too many mistakes regarding false positives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhZCg_wVha6I",
        "outputId": "072a9140-9f5c-42e1-8996-3610467b23c8"
      },
      "source": [
        "model_2_precision = model_2_tp / (model_2_tp + model_2_fp) \r\n",
        "model_2_precision"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKLk_EdIha6J"
      },
      "source": [
        "16.- Create a variable called `model_2_recall` that will calculate recall for the second model\n",
        "\n",
        "Output:\n",
        "1.0\n",
        "\n",
        "In terms of recall, the second classifier did a great job and didn't misclassify observations to false negatives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olxOM6nSha6J",
        "outputId": "5d1a98f1-b729-45e8-ee23-d1c16fb4d4b4"
      },
      "source": [
        "model_2_recall = model_2_tp / (model_2_tp + model_2_fn)\r\n",
        "model_2_recall"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t16-Wd3ha6J"
      },
      "source": [
        "17.- Create a variable called `model_2_f1` that will calculate the $F_1$ score for the second model\n",
        "\n",
        "Output:\n",
        "0.888888888888889\n",
        "\n",
        "The $F_1$ score is quite high for the second model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRB9MP2mha6J",
        "outputId": "d6e28b8f-9e1a-4177-865b-ae6657029b6f"
      },
      "source": [
        "model_2_f1 = 2 * model_2_precision * model_2_recall / (model_2_precision + model_2_recall)\r\n",
        "model_2_f1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.888888888888889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3awqWC_nha6K"
      },
      "source": [
        "In this exercise, we saw how to manually calculate the precision, recall, and $F_1$ score for two different models. The first classifier has excellent precision but bad recall, while the second classifier has excellent recall and quite good precision."
      ]
    }
  ]
}