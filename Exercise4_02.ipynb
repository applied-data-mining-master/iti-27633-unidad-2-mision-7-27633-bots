{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.02: Precision, Recall, and F1 Score Calculation\n",
    "\n",
    "In this exercise, we will calculate the precision, recall value, and the $F_1$ score of two different classifiers on a simulated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.- Import the `numpy` package as `np` using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Create a `numpy` array called `real_labels` that contains the values `[True, True, False, True, True]`. This list will represent the true values of the target variable for our simulated dataset. Print its content:\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "array([ True, True, False, True, True])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- Create a `numpy` array called `model_1_preds` that contains the values `[True, False, False, False, False]`. This list will represent the predicted values of the first classifier. Print its content.\n",
    "\n",
    "Output\n",
    "\n",
    "```\n",
    "array([ True, False, False, False, False])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.- Create another `numpy` array `called model_2_preds` that contains the values `[True, True, True, True, True]`. This list will represent the predicted values of the first classifier. Print its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.- Create a variable called `model_1_tp_cond` that will find the true positives for the first model.\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "array([ True, False, False, False, False])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.- Create a variable called `model_1_tp` that will get the number of true positives for the first model by summing `model_1_tp_cond`.\n",
    "\n",
    "Output:\n",
    "\n",
    "1\n",
    "\n",
    "There is only 1 true positive case for the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.- Create a variable called `model_1_fp` that will get the number of false positives for the first model:\n",
    "\n",
    "Output:\n",
    "\n",
    "0\n",
    "\n",
    "There is no false positive for the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.- Create a variable called `model_1_fn` that will get the number of false negatives for the first model:\n",
    "\n",
    "Output:\n",
    "3\n",
    "\n",
    "The first classifier presents 3 false negative cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.- Create a variable called `model_1_precision` that will calculate the precision for the first model:\n",
    "\n",
    "Output:\n",
    "1.0\n",
    "\n",
    "The first classifier has a precision score of 1, so it didn't predict any false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.- Create a variable called `model_1_recall` that will calculate the recall for the first model.\n",
    "\n",
    "Output:\n",
    "0.25\n",
    "\n",
    "The recall score for the first model is only $0.25$, so it is predicting quite a lot of false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.- Create a variable called `model_1_f1` that will calculate the $F_1$ score for the first model.\n",
    "\n",
    "Output:\n",
    "0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.- Create a variable called `model_2_tp` that will get the number of true positives for the second model.\n",
    "\n",
    "Output:\n",
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.- Create a variable called `model_2_fp` that will get the number of false positives for the second model\n",
    "\n",
    "Output:\n",
    "1\n",
    "\n",
    "\n",
    "There is only one false positive for the second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.- Create a variable called `model_2_fn` that will get the number of false negatives for the second model\n",
    "\n",
    "Output\n",
    "0\n",
    "\n",
    "There is no false negative for the second classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.- Create a variable called `model_2_precision` that will calculate precision for the second model:\n",
    "\n",
    "Output:\n",
    "0.8\n",
    "\n",
    "The precision score for the second model is quite high: 0.8. It is not making too many mistakes regarding false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.- Create a variable called `model_2_recall` that will calculate recall for the second model\n",
    "\n",
    "Output:\n",
    "1.0\n",
    "\n",
    "In terms of recall, the second classifier did a great job and didn't misclassify observations to false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.- Create a variable called `model_2_f1` that will calculate the $F_1$ score for the second model\n",
    "\n",
    "Output:\n",
    "0.888888888888889\n",
    "\n",
    "The $F_1$ score is quite high for the second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we saw how to manually calculate the precision, recall, and $F_1$ score for two different models. The first classifier has excellent precision but bad recall, while the second classifier has excellent recall and quite good precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
